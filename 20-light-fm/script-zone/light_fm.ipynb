{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integrated-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import fbeta_score , make_scorer\n",
    "from sklearn.model_selection import ParameterGrid# Create the parameter grid based on the results of random search \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "capital-castle",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    totalUsers  totalPlays     avgPlays\nname                                                   \nBritney Spears             522     2393140  4584.559387\nDepeche Mode               282     1301308  4614.567376\nLady Gaga                  611     1291387  2113.563011\nChristina Aguilera         407     1058405  2600.503686\nParamore                   399      963449  2414.659148\n...                        ...         ...          ...\nMorris                       1           1     1.000000\nEddie Kendricks              1           1     1.000000\nExcess Pressure              1           1     1.000000\nMy Mine                      1           1     1.000000\nA.M. Architect               1           1     1.000000\n\n[17632 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "plays = pd.read_csv('../data/user_artists.dat', sep='\\t')\n",
    "artists = pd.read_csv('../data/artists.dat', sep='\\t', usecols=['id','name'])\n",
    "\n",
    "# Merge artist and user pref data\n",
    "ap = pd.merge(artists, plays, how=\"inner\", left_on=\"id\", right_on=\"artistID\")\n",
    "ap = ap.rename(columns={\"weight\": \"playCount\"})\n",
    "\n",
    "# Group artist by name\n",
    "artist_rank = ap.groupby(['name']) \\\n",
    "    .agg({'userID' : 'count', 'playCount' : 'sum'}) \\\n",
    "    .rename(columns={\"userID\" : 'totalUsers', \"playCount\" : \"totalPlays\"}) \\\n",
    "    .sort_values(['totalPlays'], ascending=False)\n",
    "\n",
    "artist_rank['avgPlays'] = artist_rank['totalPlays'] / artist_rank['totalUsers']\n",
    "print(artist_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "political-ending",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sparsity: 0.28\n"
     ]
    }
   ],
   "source": [
    "# Merge into ap matrix\n",
    "ap = ap.join(artist_rank, on=\"name\", how=\"inner\") \\\n",
    "    .sort_values(['playCount'], ascending=False)\n",
    "\n",
    "# Preprocessing\n",
    "pc = ap.playCount\n",
    "play_count_scaled = (pc - pc.min()) / (pc.max() - pc.min())\n",
    "ap = ap.assign(playCountScaled=play_count_scaled)\n",
    "#print(ap)\n",
    "\n",
    "# Build a user-artist rating matrix \n",
    "ratings_df = ap.pivot(index='userID', columns='artistID', values='playCountScaled')\n",
    "ratings = ratings_df.fillna(0).values\n",
    "\n",
    "# Show sparsity\n",
    "sparsity = float(len(ratings.nonzero()[0])) / (ratings.shape[0] * ratings.shape[1]) * 100\n",
    "print(\"sparsity: %.2f\" % sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sensitive-poverty",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rating matrix shape (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Build a sparse matrix\n",
    "X = csr_matrix(ratings)\n",
    "\n",
    "n_users, n_items = ratings_df.shape\n",
    "print(\"rating matrix shape\", ratings_df.shape)\n",
    "\n",
    "user_ids = ratings_df.index.values\n",
    "artist_names = ap.sort_values(\"artistID\")[\"name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "casual-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "# Build data references + train test\n",
    "Xcoo = X.tocoo()\n",
    "data = Dataset()\n",
    "data.fit(np.arange(n_users), np.arange(n_items))\n",
    "interactions, weights = data.build_interactions(zip(Xcoo.row, Xcoo.col, Xcoo.data)) \n",
    "train, test = random_train_test_split(interactions)\n",
    "\n",
    "# Ignore that (weight seems to be ignored...)\n",
    "#train = train_.tocsr()\n",
    "#test = test_.tocsr()\n",
    "#train[train==1] = X[train==1]\n",
    "#test[test==1] = X[test==1]\n",
    "\n",
    "# To be completed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tight-platinum",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f1305d7bdc0>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "civic-hollow",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: train 0.37, test 0.13.\nAUC: train 0.96, test 0.85.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))\n",
    "res_warp = {'name':'warp','train_precision':train_precision,'test_precision':test_precision,'train_auc':test_auc,'test_auc':test_auc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "professional-tomato",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Depeche Mode' 'The Beatles' 'Coldplay' ... 'Robert Caldeira Jr'\n 'The Beat Daddys' 'Outbreak']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dress-japan",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f12da812f40>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model = LightFM(learning_rate=0.05, loss='bpr')\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: train 0.36, test 0.12.\nAUC: train 0.85, test 0.78.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))\n",
    "res_bpr = {'name':'bpr','train_precision':train_precision,'test_precision':test_precision,'train_auc':test_auc,'test_auc':test_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Radiohead' 'Depeche Mode' 'New Order' ... 'Katy Perry' 'Ke$ha' 'Rihanna']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f12da812e20>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model = LightFM(learning_rate=0.05, loss='logistic')\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: train 0.20, test 0.07.\nAUC: train 0.89, test 0.81.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))\n",
    "res_logistic = {'name':'logistic','train_precision':train_precision,'test_precision':test_precision,'train_auc':test_auc,'test_auc':test_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Lady Gaga' 'Britney Spears' 'Rihanna' ... 'Jennifer Rostock'\n 'Elvis Crespo' 'Sad Lovers and Giants']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f12da4a7d00>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model = LightFM(learning_rate=0.05, loss='warp-kos')\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: train 0.35, test 0.13.\nAUC: train 0.89, test 0.82.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))\n",
    "res_warp_kos = {'name':'warp_kos','train_precision':train_precision,'test_precision':test_precision,'train_auc':test_auc,'test_auc':test_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Depeche Mode' 'Pet Shop Boys' 'Moby' ... 'Nokturnal Mortum' 'Luctus'\n 'Amžius']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "res_warp :  {'name': 'warp', 'train_precision': 0.37208685, 'test_precision': 0.12747194, 'train_auc': 0.852904, 'test_auc': 0.852904}\nres_bpr :  {'name': 'bpr', 'train_precision': 0.359375, 'test_precision': 0.123196155, 'train_auc': 0.7837616, 'test_auc': 0.7837616}\nres_warp_kos :  {'name': 'warp_kos', 'train_precision': 0.34724575, 'test_precision': 0.12677713, 'train_auc': 0.82247126, 'test_auc': 0.82247126}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       name  train_precision  test_precision  train_auc  test_auc\n",
       "0      warp         0.372087        0.127472   0.852904  0.852904\n",
       "1       bpr         0.359375        0.123196   0.783762  0.783762\n",
       "2  warp_kos         0.347246        0.126777   0.822471  0.822471"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>train_precision</th>\n      <th>test_precision</th>\n      <th>train_auc</th>\n      <th>test_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>warp</td>\n      <td>0.372087</td>\n      <td>0.127472</td>\n      <td>0.852904</td>\n      <td>0.852904</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bpr</td>\n      <td>0.359375</td>\n      <td>0.123196</td>\n      <td>0.783762</td>\n      <td>0.783762</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>warp_kos</td>\n      <td>0.347246</td>\n      <td>0.126777</td>\n      <td>0.822471</td>\n      <td>0.822471</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "print(\"res_warp : \",res_warp)\n",
    "print(\"res_bpr : \",res_bpr)\n",
    "print(\"res_warp_kos : \",res_warp_kos)\n",
    "data = [res_warp,res_bpr,res_warp_kos]\n",
    "\n",
    "res_dataframe = pd.DataFrame(data = data , columns=['name','train_precision','test_precision','train_auc','test_auc'])\n",
    "res_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       WRAP  LOGISTIC       BRP  KOS-WRAP\n0  0.436055  0.219512  0.422906  0.381972\n1  0.171444  0.086417  0.158075  0.157647\n2  0.965172  0.887431  0.840421  0.888529\n3  0.858710  0.808861  0.770340  0.823018\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"WRAP\", \"LOGISTIC\", \"BRP\" ,\"KOS-WRAP\" ])\n",
    "\n",
    "loss = ['warp', 'logistic', 'bpr', 'warp-kos' ]\n",
    "\n",
    "for i,j in enumerate(loss):\n",
    "\n",
    "    model = LightFM(learning_rate=0.05, loss= j )\n",
    "    model.fit(train, epochs=10, num_threads=2)\n",
    "    a = precision_at_k(model, train, k=5).mean()\n",
    "    b = precision_at_k(model, test, k=5, train_interactions=train).mean()\n",
    "    c = auc_score(model, train).mean()\n",
    "    d = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "    this_column = df.columns[i]\n",
    "    df[this_column] = [a,b,c,d]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_ratings = csr_matrix(ratings) ### sparsing the matrix\n",
    "\n",
    "svd = TruncatedSVD(n_components=2000,n_iter=15,random_state=8)\n",
    "sparse_matrix_svd = svd.fit_transform(sparse_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_svd(userID,n_artists=30):\n",
    "    # Get the index of the movie that matches the title\n",
    "    \n",
    "    cosine_sim = linear_kernel(sparse_matrix_svd, sparse_matrix_svd[userID].reshape(1,-1))\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim))\n",
    "    \n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:n_artists + 1]\n",
    "    \n",
    "    # Get the movie indices\n",
    "    users_indices = [i[0] for i in sim_scores]\n",
    "    artist_top = []\n",
    "    for i in users_indices:\n",
    "        idx_i = np.argmax(ratings[i]) # take the most important artist for this user\n",
    "        if ap['name'][ap['artistID']==idx_i].unique()[0] not in artist_top:\n",
    "            artist_top.append(ap['name'][ap['artistID']==idx_i].unique()[0])\n",
    "    \n",
    "    # Return the top 10 most similar movies\n",
    "    return artist_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Mindless Self Indulgence',\n",
       " 'Faithless',\n",
       " 'Gothminister',\n",
       " 'Reaper',\n",
       " 'Funeral for a Friend',\n",
       " 'James Blunt',\n",
       " 'Talk Talk',\n",
       " 'Cock Robin',\n",
       " 'Thievery Corporation',\n",
       " 'Ana Carolina',\n",
       " 'Zornik',\n",
       " 'Dope']"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "artist_top = get_recommendations_svd(0)\n",
    "artist_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['a-ha' 'Orchestral Manoeuvres in the Dark' 'Duran Duran' 'Depeche Mode'\n 'Robbie Williams' 'The Human League' 'Ultravox' 'Yazoo' 'George Michael'\n 'Japan']\n"
     ]
    }
   ],
   "source": [
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_items([('loss', 'logistic'), ('learning_schedule', 'adadelta'), ('learning_rate', 0.05)])"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "# Optimisation de paramètres avec GridSearch\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid# Create the parameter grid based on the results of random search \n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05 , 0.08],\n",
    "    'learning_schedule':['adagrad','adadelta'],\n",
    "    'loss': ['warp','bpr','logistic','warp-kos']\n",
    "    \n",
    "}\n",
    "# definition liste score auc\n",
    "auc_score_values = []\n",
    "\n",
    "for grid in ParameterGrid(param_grid):\n",
    "    model = LightFM(**grid)\n",
    "    pred = model.fit(train)\n",
    "    auc_score_values.append(round(auc_score(model, test, train_interactions=train).mean(),3))\n",
    "    \n",
    "max_value = max(auc_score_values) \n",
    "max_index = np.argmax(auc_score_values)\n",
    "ParameterGrid(param_grid)[max_index ].items()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}